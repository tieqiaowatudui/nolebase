插入排序算法是从一个待排序数组中,不断选出其中最小的元素,移动到已经排序数组的最后面.插入排序是前面有序,后面无序,逐步变成全局有序的转变.
由于插入排序的时间复杂度是O(n^2),是一种效率较低的算法.所以做了优化没到局部有序,只有在获取最小和插入消耗较小,同时在时间复杂度变为O($log_2n$)的排序.
# 堆的结构
堆分为大根堆和小根堆.其中:
- 父节点最大是大根堆
- 父节点最小是小根堆
堆使用了数组的方式来存放所有的数据.这样能够有效的提升空间使用效率.整个序列从数组的1开始存放.任意一个节点i,其父节点和左右孩子节点的位置为:
```python
# 这个堆的 root节点rank = 1 不是从0开始.
# 如果是从0 开始  
#      l_child = i * 2 +1
#      r_child = i * 2 + 2
#      parent = (i-1) // 2
def parent(i) -> int:
	return i //2

def left_child(i) -> int:
	return i * 2	

def right_child(i) -> int:
	return i * 2 + 1

```
这里确定了任意一个节点i他的左右子树的节点都比 i节点大或者小.
因为使用了数组来存放整个堆,而堆的结构是一个完全二叉树的结构,优点是提升了空间使用效率.缺点是:当插入新节点的时候需要移动大量的数据.

# 构建堆
> 将新数写入到堆的最后的位置,然后一路往上爬,这和冒泡排序有点类似
将新插入的数据,写到堆最后的位置,然后计算出parent节点的位置,然后进行比较.如果小于就交换当前节点和parent节点的位置.然后一路比较上去.

# 提取最小元素
堆中的最小元素在堆顶,我们需要做的事情是将堆顶的元素取出,然后用堆最后的元素存放在堆顶.这样会导致堆结构失效.这个时候就需要调整对的结构.
这个过程是一个下沉的过程.就是比较堆顶的元素和两个子孩子中更小的元素,然后选择交换值,然后继续进行下沉.直到下沉到最后.
下沉的过程是一个递归的过程,因为任何一个位置的节点都可以看成是一个子堆的根.这样就能够不断地下沉了.
堆排的实现就是通过[[#提取最小元素]]实现的,就是不断的将堆顶的元素取出来,然后用堆最后的元素替换,然后信息下沉.最终在原地实现排序.
# 建堆过程的优化
我们正常的方式是自顶向下的建堆,不断的将元素加入到堆的最后一个元素中然后对堆进行bubble_up这样不断的建成一个堆.这里时间复杂度是 O(nlogn).
还有一种是自底向上,假设已知了所有的元素,然后将所有元素添加到数组中,其中后一半`[n//2,n-1]`这一半是叶子节点不需要进行bubble_down.值需要对`[0,n//2-1]`这些元素进行bubble_down.就可以完成了整个树的构建.
由于 1/2不需要下沉,1/4只需要一次下沉,....只有一个需要$log_2n$次下沉.最终的和是 O(n)
这种自底向上的建堆的前提是堆中的元素是确定的,但是很多时候堆中的元素是不断的添加和删除,所以最差的堆排序还是O(n$log_2n$)
# 如何确定堆中第k大的元素是否小于等于 x
这种实现可以用递归来实现,优先访问左子树,然后访问右子树.
```python
def heap_compare(self,heap,idx,count ,x)--> int:
	if count <= 0 || idx >= len(heap):
		return count
	if head[idx] <= x:
		count = self.heap_compare(heap,self.l_child(idx),count-1,x)
		count = self.head_compare(head,self.r_child(idx),count,x)
	return count
```

> 上面这个算法count初始是k,表示不小于等于x的元素剩余k个.然后依次从根开始进行比较下去遇到了 count <= 0 表示满足了要求,如果堆结束了就返回对应的元素.

# 堆的使用场景
堆可以适用于排序的场景中.但是堆更加优秀的是堆的使用场景.就是构建一个堆,不断的写入新的数据,然后快速拿出当前堆中最小的数据的场景.
例如不断的塞选最优惠的券的时候,因为券是不断变化的.所以使用堆更合适.

## **4.5 归并排序：一种分治法排序**

递归算法的思想是将大问题分解为更小的问题。用于排序的递归方法是将元素分成两个部分，对每个较小的子问题递归排序，然后将两个已排序好的列表按顺序合并（interleave）成一个完全有序的列表。这种算法称为 _归并排序（mergesort）_，名字强调了“合并”操作的重要性。
```c
Mergesort(A[1, n]) 
    Merge(
        MergeSort(A[1, n/2]),
        MergeSort(A[n/2+1, n])
    )

```

递归的基础情况是：当待排序的子数组只剩一个元素时，此时已无法再 rearrange，因此可以直接认为已排序。
![[Pasted image 20251207104534.png]]
图 4.4 展示了归并排序的执行过程示意图。可以想象成在上方的树中做一次中序遍历，而下方的“镜像树”展示了对应的数组变化情况。

---
归并排序的效率取决于我们将两个已排序的部分合并成一个有序列表的效率。我们可以把两个部分简单拼在一起，然后调用堆排序或其他排序方法来处理，但这么做会让我们在前面递归排序中所做的工作完全白费。
我们应该采用“归并”方法合并两个列表。注意：两个按递增顺序排序的列表中，全局最小值一定位于其中一个列表的开头。我们取出这个最小值后，列表仍然各自有序。接着，全局第二小的值又会出现在接下来两个列表的开头……如此反复，直到两个列表都空为止。这一过程能将两个总大小为 n 的有序列表合并成一个，用比较次数不超过 n−1 次，即 O(n) 时间。

---

归并排序的总时间是多少？我们可以从递归执行树的每一层来观察所做的工作量。如果为方便假设 n 是 2 的幂，则第 k 层包含 2^k 个归并调用，每个子问题的大小为 n/2^k。
- 第 0 层（k=0）的工作是将大小为 n/2 的两个已排序列表合并，总共需要不超过 n−1 次比较。
- 第 1 层（k=1）有两个大小为 n/4 的合并操作，总共不超过 n−2 次比较。
- 一般来说，第 k 层有 2^k 对大小为 n/2^(k+1) 的列表要合并，总比较次数不超过 n − 2^k。
可以看到，每一层的合并工作量都是线性的。每个元素在每一层只参与一次子问题。因此每层的总工作量大约为 n，最耗时的层反而是递归树的最顶部。
子问题的大小每下一层就减半，所以总层数为 ⌈log2 n⌉。因此归并排序的总时间复杂度为：
**O(n log n)**（最坏情况）。

---

归并排序非常适合用于链表，因为它不需要像堆排序或快速排序那样依赖随机访问。它的主要缺点是在操作数组时需要额外的缓冲区。对于链表，只需调整指针即可完成合并，不需要额外空间。
但如果要合并两个排序好的数组（或数组中两个已排序部分），必须使用第三个数组作为缓冲区，否则会覆盖数据。例如：
把数组 `{4, 5, 6}` 和 `{1, 2, 3}` 放在同一个数组的左右两边，如果没有缓冲区，在合并时会把上半部分的数据覆盖掉，导致数据丢失。

---
归并排序是典型的分治算法。当我们能把一个大问题拆成两个更小的问题时往往能更省力，因为小问题更容易解决。关键在于：如何利用两个子问题的部分结果构造整个问题的最终解，而归并操作正是这种思想的经典体现。

### **实现（Implementation）**

分治法的归并排序程序直接按照伪代码实现即可：

```c
mergesort(item_type s[], int low, int high) {
    int i;            /* 计数器 */
    int middle;       /* 中间元素的索引 */

    if (low < high) {
        middle = (low + high) / 2;
        mergesort(s, low, middle);
        mergesort(s, middle + 1, high);
        merge(s, low, middle, high);
    }
}
```

更具挑战性的部分在于“合并”操作的具体细节。问题在于合并过程中必须有地方存放已合并的结果。如果直接在原数组中一边读一边写，很可能覆盖还未读取的元素，导致数据丢失。

为避免覆盖问题，我们先将两个子数组分别复制到两个队列中，然后再把从队列中取出的较小元素按顺序写回原数组。具体实现如下：

```c
merge(item_type s[], int low, int middle, int high) {
    int i;                    /* 计数器 */
    queue buffer1, buffer2;   /* 用来保存子数组元素的缓冲队列 */

    init_queue(&buffer1);
    init_queue(&buffer2);

    for (i = low; i <= middle; i++)
        enqueue(&buffer1, s[i]);

    for (i = middle + 1; i <= high; i++)
        enqueue(&buffer2, s[i]);

    i = low;

    /* 比较两个队列的队头元素，把较小的取出放回数组 */
    while (!(empty_queue(&buffer1) || empty_queue(&buffer2))) {
        if (headq(&buffer1) <= headq(&buffer2))
            s[i++] = dequeue(&buffer1);
        else
            s[i++] = dequeue(&buffer2);
    }

    /* 将剩余元素写回原数组 */
    while (!empty_queue(&buffer1))
        s[i++] = dequeue(&buffer1);

    while (!empty_queue(&buffer2))
        s[i++] = dequeue(&buffer2);
}

```

## 4.6 快速排序：利用随机化进行排序
假设我们从要排序的 n 个元素中随机选择一个元素 p 作为主元。快速排序（其过程如图4.5所示）将剩下的 n − 1 个元素分成两堆：
- **低堆（low pile）**：包含所有在最终排序中排在 p 前面的元素
- **高堆（high pile）**：包含所有在最终排序中排在 p 后面的元素
low 与 high 指代数组中放置这些元素的位置，两者之间留下一个空位给主元 p。
这样的划分带来两个好处：
1. 主元 p 最终会落在它在最终排序中的正确位置上。
2. 在划分完成后，没有任何元素会在最终排序中“翻到另一边”。
因此我们只需要独立地对主元左边与右边的元素继续排序即可！这自然形成了一个递归排序算法，因为我们可以对每个子问题继续使用这个划分方法。该算法必然正确，因为最终每个元素都会落到正确的位置。

```c
quicksort(item_type s[], int l, int h) {
    int p; /* 划分位置 */
    if ((h - l) > 0) {
        p = partition(s, l, h);
        quicksort(s, l, p-1);
        quicksort(s, p+1, h);
    }
}
```

对于给定的主元，我们可以通过一次线性扫描完成划分：维护数组中的三个区域：
- 小于主元的元素（firsthigh 左边）
- 大于或等于主元的元素（位于 firsthigh 和 i 之间）
- 未探索区域（i 右边）

实现如下：
```c 
int partition(item_type s[], int l, int h) {
    int i;
    int p;
    int firsthigh;
    p = h;
    firsthigh = l;

    for (i = l; i < h; i++)
        if (s[i] < s[p]) {
            swap(&s[i], &s[firsthigh]);
            firsthigh++;
        }
    swap(&s[p], &s[firsthigh]);
    return firsthigh;
}

```

由于划分步骤最多执行 n 次交换，因此其时间复杂度是线性的。
现在我们讨论整个快速排序的运行时间。和归并排序类似，快速排序构建了一个对 n 个元素不断划分的递归树。和归并排序一样，每一层都需要线性时间（此处为划分，而不是合并）。因此快速排序的整体复杂度为 O(n · h)，其中 h 是递归树的高度。

问题在于：**递归树的高度取决于主元的位置**。
- 如果非常幸运，每次都选到中位数作为主元，子问题大小都减半，递归高度为 ⌈log₂ n⌉，这对应于最优情况（图4.6左）。
- 如果非常不幸，每次主元都是当前数组的最大值或最小值，那么子问题总是 n − 1、n − 2、……，形成高度为 n − 1 的链状树（图4.6右），此时时间复杂度为 Θ(n²)。
因此，快速排序的最坏情况比堆排序或归并排序更差。  
为了“对得起它的名字”（quick），快速排序必须在平均情况下表现优秀。要理解为什么需要一些关于随机采样的直觉。